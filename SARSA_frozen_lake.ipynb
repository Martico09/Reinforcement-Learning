{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N3K6EGmsiNJz","executionInfo":{"status":"ok","timestamp":1684219822470,"user_tz":-330,"elapsed":9029,"user":{"displayName":"ANIMESH GUPTA (RA2011047010021)","userId":"03973304669749828208"}},"outputId":"8dde4a1c-61bb-46e4-b7d4-230b1a33ee24"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.25876907 0.23879996 0.23803605 0.23096059]\n"," [0.11866574 0.11403757 0.13300786 0.21365296]\n"," [0.19503694 0.17000915 0.14639205 0.14812399]\n"," [0.10365165 0.04539578 0.01606758 0.06036132]\n"," [0.29205401 0.17407049 0.2264924  0.13592705]\n"," [0.         0.         0.         0.        ]\n"," [0.21726968 0.07956192 0.12123048 0.08414007]\n"," [0.         0.         0.         0.        ]\n"," [0.2114673  0.23294224 0.18368418 0.34209398]\n"," [0.18976728 0.38362609 0.31831717 0.25304019]\n"," [0.42734518 0.26044887 0.35093428 0.15169826]\n"," [0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.        ]\n"," [0.1954622  0.34039069 0.50674481 0.42125808]\n"," [0.49753341 0.58198447 0.60263119 0.692796  ]\n"," [0.         0.         0.         0.        ]]\n"]}],"source":["import gym\n","import numpy as np\n","\n","# Create the FrozenLake environment\n","env = gym.make('FrozenLake-v1')\n","\n","# Set the parameters\n","num_episodes = 10000\n","learning_rate = 0.1\n","discount_factor = 0.99\n","epsilon = 0.1\n","\n","# Initialize the Q-table\n","state_space = env.observation_space.n\n","action_space = env.action_space.n\n","q_table = np.zeros((state_space, action_space))\n","\n","# Function to choose an action based on epsilon-greedy strategy\n","def choose_action(state):\n","    if np.random.uniform(0, 1) < epsilon:\n","        # Explore: Choose a random action\n","        return env.action_space.sample()\n","    else:\n","        # Exploit: Choose the action with the highest Q-value\n","        return np.argmax(q_table[state, :])\n","\n","# SARSA algorithm\n","for episode in range(num_episodes):\n","    state = env.reset()\n","    action = choose_action(state)\n","    done = False\n","\n","    while not done:\n","        next_state, reward, done, _ = env.step(action)\n","        next_action = choose_action(next_state)\n","\n","        # Update the Q-table using the SARSA update rule\n","        q_table[state, action] += learning_rate * (\n","                reward + discount_factor * q_table[next_state, next_action] - q_table[state, action])\n","\n","        state = next_state\n","        action = next_action\n","\n","# Print the learned Q-table\n","print(q_table)\n","\n","# Close the environment\n","env.close()\n"]},{"cell_type":"code","source":["import numpy as np \n","import gym\n","\n","env = gym.make('FrozenLake-v1')\n","\n","num_episodes = 10000\n","learning_rate = 0.1\n","discount_factor = 0.99\n","epsilon = 0.1\n","\n","state_space = env.observation_space.n\n","action_space = env.action_space.n\n","q_table = np.zeros((state_space,action_space))\n","\n","\n","def choose_action(state):\n","  if np.random.uniform(0,1) < epsilon:\n","    return env.action_space.sample()\n","  else:\n","    return np.argmax(q_table[state,:])\n","\n","for episode in range(num_episodes):\n","  state = env.reset()\n","  action = choose_action(state)\n","  done = False\n","\n","  while not done:\n","    next_state, reward, done, _ = env.step(action)\n","    next_action = choose_action(next_state)\n","\n","    q_table[state,action] += learning_rate*(reward + discount_factor*q_table[next_state,next_action] - q_table[state,action])\n","\n","    state = next_state\n","    action = next_action\n","\n","print(q_table)\n","env.close() "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JpJoBD2niNrj","executionInfo":{"status":"ok","timestamp":1684219884124,"user_tz":-330,"elapsed":7737,"user":{"displayName":"ANIMESH GUPTA (RA2011047010021)","userId":"03973304669749828208"}},"outputId":"bb2182b3-6781-4231-9182-419137224357"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.05172114 0.04139756 0.03854514 0.04709246]\n"," [0.0369702  0.00597369 0.00066492 0.00575708]\n"," [0.00760772 0.         0.         0.        ]\n"," [0.         0.         0.         0.        ]\n"," [0.05783639 0.04667535 0.03240354 0.02572372]\n"," [0.         0.         0.         0.        ]\n"," [0.04478876 0.         0.         0.        ]\n"," [0.         0.         0.         0.        ]\n"," [0.02236335 0.03171724 0.03974446 0.0706408 ]\n"," [0.0803139  0.06224499 0.05762617 0.04127075]\n"," [0.19453813 0.         0.         0.        ]\n"," [0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.        ]\n"," [0.04793232 0.19959425 0.08629607 0.0938519 ]\n"," [0.0835237  0.19       0.03393359 0.41602378]\n"," [0.         0.         0.         0.        ]]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"BttfyLiWdZKx"},"execution_count":null,"outputs":[]}]}